import json
import logging
import os
import threading
from ryu.base import app_manager
from ryu.controller import ofp_event
from ryu.controller.handler import MAIN_DISPATCHER, DEAD_DISPATCHER, CONFIG_DISPATCHER, set_ev_cls
from ryu.ofproto import ofproto_v1_3
from ryu.lib.packet import packet, ethernet, ether_types
from ryu.topology import event
from ryu.topology.api import get_link
from ryu.app.wsgi import WSGIApplication
from flow_allocator_handler_websocket import FlowWebSocketHandler
from path_finder import PathFinder
import time

RESERVATION_EXPIRE_TIME = 60  # seconds

class FlowAllocator(app_manager.RyuApp):
    OFP_VERSIONS = [ofproto_v1_3.OFP_VERSION]
    _CONTEXTS = {'wsgi': WSGIApplication}

    def __init__(self, *args, **kwargs):
        """
        Initialize the FlowAllocator class.
        This class acts as a flow allocation controller that manages network flows, WebSocket connections, 
        and maintains network topology information. It sets up logging, initializes a WebSocket server,
        and maintains various data structures for network management.
        Args:
            *args: Variable length argument list.
            **kwargs: Arbitrary keyword arguments.
        Attributes:
            websocket_handler (FlowWebSocketHandler): Handles WebSocket connections for flow management
            host_to_switch (dict): Mapping of hosts to their connected switches
            flow_reservations (dict): Stores active flow reservations
            links (dict): Network topology links information
            datapaths (dict): Stores OpenFlow switch datapaths
            flow_capacity (dict): Network link capacity information
            path_finder (PathFinder): Handles path computation between network nodes
        """

        super(FlowAllocator, self).__init__(*args, **kwargs)
        
        # Configure the logger
        formatter = logging.Formatter("[%(funcName)s] %(message)s")
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(formatter)
        self.logger.addHandler(console_handler)
        
        # Avoid duplicating logs
        self.logger.propagate = False
        
        self.logger.setLevel("INFO")
        self.logger.info("Initializing FlowAllocator...")
        
        
        # Start the WebSocket server in a separate thread
        self.websocket_handler = FlowWebSocketHandler(flow_allocator=self, host="0.0.0.0", port=8765, logger=self.logger)
        threading.Thread(target=self.websocket_handler.start, daemon=True).start()
        self.logger.info("WebSocket handler started!")
        
        self.host_to_switch = {}
        self._init_host_to_switch()
        
        self.flow_reservations = {}
        
        self.links = {}  

        self.datapaths = {}
        
        self.flow_capacity = {}
        self._init_flow_capacity()

        self.path_finder = PathFinder(self.flow_capacity, self.logger)
        
        # start a thread to periodically check for expired reservations
        threading.Thread(target=self._check_reservation_expiry, daemon=True).start()
                
        self.qos_queues = {}  # (dpid, port) -> {queue_id: bandwidth}
        self.next_queue_id = 1  # start from 1 (0 is usually best-effort)
            
    def _init_host_to_switch(self):
        """
        Reads `/tmp/host_info.json` and initializes the host_to_switch dictionary.
        """
        self.logger.info("Initializing host_to_switch dictionary from Mininet output...")

        # Path to the JSON file generated by Mininet
        host_info_file = "/tmp/host_info.json"

        if not os.path.exists(host_info_file):
            self.logger.error(f"Host info file not found: {host_info_file}")
            return False

        try:
            with open(host_info_file, "r") as f:
                host_info: dict = json.load(f)

            # Populate the map using MAC as key and also save the host name
            for host_name, details in host_info.items():
                mac = details["mac"]
                self.host_to_switch[mac] = {
                    "name": host_name,
                    "connected_switch": details["connected_switch"],
                    "src_port": details["src_port"]
                }

            self.logger.info(f"Host-to-switch mapping initialized: {self.host_to_switch}")
            return True

        except json.JSONDecodeError:
            self.logger.error("Error decoding JSON file. Ensure Mininet has generated the file correctly.")
            return False

        except Exception as e:
            self.logger.error(f"Unexpected error reading host info file: {e}")
            return False
    
    def _init_flow_capacity(self):
        """
        Initializes the flow capacity dictionary based on bandwidth info from switch_links_info.json
        """
        self.logger.info("Initializing flow capacity dictionary...")

        # Read the JSON file
        try:
            with open("/tmp/switch_links_info.json", "r") as f:
                switch_links = json.load(f)
        except FileNotFoundError:
            self.logger.error("switch_links_info.json not found")
            return
        except json.JSONDecodeError:
            self.logger.error("Error decoding switch_links_info.json")
            return
        
        self.logger.info(f"Switch links info: {switch_links}")

        # Process each link
        for link_str, info in switch_links.items():
            # Parse switches from string like "s1-s2"
            sw1, sw2 = link_str.split("-")
            sw1_id = int(sw1.lstrip("s"))
            sw2_id = int(sw2.lstrip("s"))
            
            # Get bandwidth, default to 10 if not specified
            bw = info.get("bandwidth", 10)

            # Add both directions to flow capacity
            self.flow_capacity[(sw1_id, sw2_id)] = bw
            self.flow_capacity[(sw2_id, sw1_id)] = bw

        self.logger.info(f"Flow capacities initialized: {self.flow_capacity}")

    @set_ev_cls(ofp_event.EventOFPStateChange, [MAIN_DISPATCHER, DEAD_DISPATCHER])
    def state_change_handler(self, ev):
        """
        Handles state changes in the OpenFlow switches.
        This method tracks switch connections and disconnections, updating the internal
        datapath dictionary accordingly. It logs when switches connect or disconnect
        from the controller.
        Args:
            ev (ryu.controller.event.EventSwitchBase): Event containing switch state change information
                - ev.datapath: The switch's datapath object
                - ev.state: The new state of the switch
        Side effects:
            - Updates self.datapaths dictionary
            - Logs switch connection/disconnection events
        """

        datapath = ev.datapath
        if ev.state == MAIN_DISPATCHER:
            self.datapaths[datapath.id] = datapath  # Add datapath
            self.logger.info(f"Switch connected: dpid={datapath.id}")
        elif ev.state == DEAD_DISPATCHER:
            self.datapaths.pop(datapath.id, None)  # Remove datapath
            self.logger.info(f"Switch disconnected: dpid={datapath.id}")

    @set_ev_cls(ofp_event.EventOFPSwitchFeatures, CONFIG_DISPATCHER)
    def switch_features_handler(self, ev):
        """
        Handle switch features reply to negotiate OpenFlow version.
        This method is called when a switch connects to the controller and sends its features.
        It sets up the initial configuration for the switch by installing a default flow rule
        that sends all packets to the controller.
        Parameters
        ----------
        ev : ryu.controller.event.EventSwitchFeatures
            Event containing information about the connected switch including the datapath object.
        ----
        The default rule installed has the lowest priority (0) and matches all packets,
        sending them to the controller for processing.
        """
        datapath = ev.msg.datapath
        dpid = datapath.id  # Datapath ID of the switch
        self.logger.info(f"Switch connected: dpid={dpid}")
        ofproto = datapath.ofproto
        parser = datapath.ofproto_parser
        
        # Default rule to handle all packets
        match = parser.OFPMatch()
        actions = [parser.OFPActionOutput(ofproto.OFPP_CONTROLLER, ofproto.OFPCML_NO_BUFFER)]
        self.add_flow(datapath, 0, match, actions)

    def add_flow(self, datapath, priority, match, actions):
        """
        Add a flow entry to the OpenFlow switch.
        This method installs a flow rule in the switch's flow table using OpenFlow protocol.
        The flow rule specifies how to handle packets that match certain criteria.
        Args:
            datapath: The switch object representing the OpenFlow switch
            priority: Integer indicating the priority of this flow rule
            match: Match object defining the packet match criteria
            actions: List of action objects defining what to do with matching packets
        """
        ofproto = datapath.ofproto
        parser = datapath.ofproto_parser
        # Create flow mod message
        inst = [parser.OFPInstructionActions(ofproto.OFPIT_APPLY_ACTIONS, actions)]
        mod = parser.OFPFlowMod(
            datapath=datapath, priority=priority, match=match, instructions=inst
        )
        self.logger.debug(f"Adding flow: match={match}, actions={actions}")
        datapath.send_msg(mod)
        self.logger.info(f"Flow added successfully.")
    
    def _delete_flow(self, datapath, match):
        ofproto = datapath.ofproto
        parser = datapath.ofproto_parser
        mod = parser.OFPFlowMod(
            datapath=datapath, command=ofproto.OFPFC_DELETE, out_port=ofproto.OFPP_ANY, out_group=ofproto.OFPG_ANY,
            match=match
        )
        self.logger.debug(f"Deleting flow: match={match}")
        datapath.send_msg(mod)
        self.logger.info(f"Flow deleted successfully.")
         
    # ------------------------------------------------
    # 2) Topology (SwitchEnter, LinkAdd, LinkDelete)
    # ------------------------------------------------
    @set_ev_cls(event.EventSwitchEnter)
    def switch_enter_handler(self, ev):
        """
        Handler function for switch enter events in the network.
        This method is triggered when a new switch enters the network topology. It updates
        the network topology information and logs changes in network links.
        Args:
            ev (EventSwitchEnter): Event object containing information about the switch
                that entered the network. Contains the switch datapath object.
        Attributes modified:
            self.links: Dictionary storing the current network link information
        """
        
        old_links = dict(self.links)
        self.logger.info(f"Switch entered: {ev.switch.dp.id}")
        # self._get_topology_data()
        if old_links != self.links:
            self.logger.info(f"Switch added. Updated links: {self.links}")

    @set_ev_cls(event.EventLinkAdd)
    def link_add_handler(self, ev):
        """
        Handler function for link addition events in the network topology.
        This method is triggered when a new link is added to the network. It updates the
        topology information by calling _get_topology_data() to refresh the network view.
        Parameters:
            ev: ryu.topology.event.EventLinkAdd
                The event object containing information about the added link.
        """

        self._get_topology_data()

    @set_ev_cls(event.EventLinkDelete)
    def link_delete_handler(self, ev):
        """
        Handles link deletion events in the network.
        This method is triggered when a link is deleted from the network topology.
        It logs information about the deleted link and the updated network links.
        Args:
            ev: The link deletion event object containing details about the deleted link
        """

        self.logger.info(f"Link deleted. Updated links: {self.links}")
        
    def _get_topology_data(self):
        """
        Updates topology data by collecting information from get_switch() and get_link().
        """
        # Resets the dictionaries
        self.links.clear()
                
        # Gets the link data
        link_list = get_link(self, None)
        for link in link_list:
            src_dpid = int(link.src.dpid)
            dst_dpid = int(link.dst.dpid)
            src_port_no = int(link.src.port_no)
            dst_port_no = int(link.dst.port_no)

            # Maps the links in the dictionaries
            self.links[(src_dpid, dst_dpid)] = {
                "src_port": src_port_no,
                "dst_port": dst_port_no,
                "src_hw_addr": link.src.hw_addr,
                "dst_hw_addr": link.dst.hw_addr,
            }
    
    # 1. Endpoint for flow allocation
    def allocate_flow(self, src_mac, dst_mac, bandwidth):
        """
        Reserves network flow between two hosts with specified bandwidth requirements.
        This function performs the following operations:
        1. Validates source and destination MAC addresses
        2. Finds a path with sufficient bandwidth between hosts
        3. Updates network capacity along the chosen path
        5. Records the flow reservation
        Args:
            src_mac (str): Source host MAC address
            dst_mac (str): Destination host MAC address 
            bandwidth (float): Required bandwidth in Mbps
        """
        # Check if src_mac and dst_mac exist in host_to_switch mapping
        if src_mac not in self.host_to_switch or dst_mac not in self.host_to_switch:
            self.logger.error(f"Host not found: {src_mac} -> {dst_mac}")
            return False

        src_details = self.host_to_switch[src_mac]
        dst_details = self.host_to_switch[dst_mac]

        # Converts the switch string (e.g., "s1") into dpid (int)
        src_dpid = int(src_details["connected_switch"].lstrip("s"))
        dst_dpid = int(dst_details["connected_switch"].lstrip("s"))

        src_datapath = self.datapaths.get(src_dpid)
        if src_datapath is None:
            self.logger.error(f"Datapath not found for dpid: {src_dpid}")
            return False

        dst_datapath = self.datapaths.get(dst_dpid)
        if dst_datapath is None:
            self.logger.error(f"Datapath not found for dpid: {dst_dpid}")
            return False

        # Create dictionaries for switches for path_finder
        src_switch = {"dpid": src_dpid}
        dst_switch = {"dpid": dst_dpid}

        # Find the path with enough bandwidth
        path, available_bandwidth = self.path_finder.find_max_bandwidth_path(src_switch, dst_switch, bandwidth)
        if not path:
            self.logger.error("No path found with sufficient bandwidth.")
            return False

        self.logger.info(f"Path found: {path}, available bandwidth: {available_bandwidth} Mbps")

        # Update remaining capacity and install flows
        for i in range(len(path) - 1):
            link = (path[i], path[i + 1])
            reverse_link = (path[i + 1], path[i])
            self.flow_capacity[link] -= bandwidth
            self.flow_capacity[reverse_link] -= bandwidth
            self.path_finder.link_capacities[link] = self.flow_capacity[link]
            self.path_finder.link_capacities[reverse_link] = self.flow_capacity[reverse_link]
        
        self.path_finder.build_graph()  # Rebuild the graph

        self.flow_reservations[(src_mac, dst_mac)] = {
            "path": path,
            "bandwidth": bandwidth,
            "start_time": time.time(),
            "installed": False
        }
        self.logger.info(f"Flow reservation added: {src_mac} -> {dst_mac}")
        return True
    
    # 2. Endpoint for deleting a flow
    def delete_flow(self, src_mac, dst_mac):
        """
        Delete a flow reservation and allocation and restore network capacity.
        This function removes a previously established flow between two MAC addresses,
        restores the bandwidth capacity along the path, and deletes the corresponding
        flow rules from the switches.
        Args:
            src_mac (str): Source MAC address of the flow
            dst_mac (str): Destination MAC address of the flow
        """
        reservation = self.flow_reservations.get((src_mac, dst_mac))
        if not reservation:
            self.logger.error(f"Flow not found: {src_mac} -> {dst_mac}")
            return False

        path = reservation["path"]
        bandwidth = reservation["bandwidth"]

        # Restore the flow capacity
        for i in range(len(path) - 1):
            link = (path[i], path[i + 1])
            reverse_link = (path[i + 1], path[i])
            self.flow_capacity[link] += bandwidth
            self.flow_capacity[reverse_link] += bandwidth
            self.path_finder.link_capacities[link] = self.flow_capacity[link]
            self.path_finder.link_capacities[reverse_link] = self.flow_capacity[reverse_link]
        
        self.path_finder.build_graph()
        
        self.flow_reservations.pop((src_mac, dst_mac))
        self.logger.info(f"Flow reservation deleted: {src_mac} -> {dst_mac}")
        
        # Delete flow rules
        self.delete_path_flows(path, src_mac, dst_mac)
        self.delete_path_flows(path[::-1], dst_mac, src_mac)
        
        return True
    
    def show_reservation(self):
        """
        Returns all current flow reservations as a dictionary.
        Returns:
            dict: Dictionary containing all flow reservations and their details
        """
        try:
            reservations = {}
            for (src_mac, dst_mac), reservation in self.flow_reservations.items():
                path = reservation["path"]
                bandwidth = reservation["bandwidth"]
                start_time = reservation["start_time"]
                installed = reservation["installed"]
                elapsed = time.time() - start_time

                reservations[f"{src_mac}->{dst_mac}"] = {
                    "path": path,
                    "bandwidth": bandwidth,
                    "elapsed_time": f"{elapsed:.2f}",
                    "start_time": start_time,
                    "installed": installed
                }
            
            print(f"Reservations: {reservations}")  # Log the reservations
            return reservations
        except Exception as e:
            print(f"Error in show_reservation: {str(e)}")
            return {}
    
    def _check_reservation_expiry(self):
        """
        Periodically checks for expired flow reservations and restores network capacity.
        This function runs in a separate thread and checks the flow_reservations dictionary
        for any reservations that have exceeded their expiration time (RESERVATION_EXPIRE_TIME seconds).
        If an expired reservation is found, it restores the network capacity and deletes the reservation.
        """
        while True:
            time.sleep(10)
            current_time = time.time()
            expired_reservations = []
            for (src_mac, dst_mac), reservation in list(self.flow_reservations.items()):
                elapsed_time = current_time - reservation["start_time"]
                
                if not reservation["installed"] and elapsed_time > RESERVATION_EXPIRE_TIME:
                    self.logger.info(f"Flow reservation expired: {src_mac} -> {dst_mac}")
                    expired_reservations.append((src_mac, dst_mac))
                    path = reservation["path"]
                    bandwidth = reservation["bandwidth"]
                    
                    # Restore the flow capacity
                    for i in range(len(path) - 1):
                        link = (path[i], path[i + 1])
                        reverse_link = (path[i + 1], path[i])
                        self.flow_capacity[link] += bandwidth
                        self.flow_capacity[reverse_link] += bandwidth
                        self.path_finder.link_capacities[link] = self.flow_capacity[link]
                        self.path_finder.link_capacities[reverse_link] = self.flow_capacity[reverse_link]
                    
                    self.path_finder.build_graph()  # Rebuild the graph
                    self.logger.info(f"Flow capacity restored for {src_mac} -> {dst_mac}.")    
                    self.flow_reservations.pop((src_mac, dst_mac))
                    
    def check_reservation(self, src_mac, dst_mac):
        """
        Validates a flow reservation and allocates the correspanded flow between between two hosts.
        This function checks if there is an existing flow reservation between the specified source
        and destination MAC addresses, verifies if it hasn't expired, and installs the necessary
        flow rules if valid. If the reservation has expired, it restores the network capacity.
        Args:
            src_mac (str): Source host MAC address
            dst_mac (str): Destination host MAC address
        """
        
        reservation = self.flow_reservations.get((src_mac, dst_mac))
        if not reservation:
            self.logger.error(f"Flow not found: {src_mac} -> {dst_mac}")
            return False

        path = reservation["path"]
        bandwidth = reservation["bandwidth"]
        start_time = reservation["start_time"]
        current_time = time.time()
        elapsed_time = current_time - start_time

        # Check if the reservation has expired
        if elapsed_time > RESERVATION_EXPIRE_TIME:
            self.logger.error(f"Flow reservation expired: {src_mac} -> {dst_mac}")
            for i in range(len(path) - 1):
                link = (path[i], path[i + 1])
                reverse_link = (path[i + 1], path[i])
                self.flow_capacity[link] += bandwidth
                self.flow_capacity[reverse_link] += bandwidth
                self.path_finder.link_capacities[link] = self.flow_capacity[link]
                self.path_finder.link_capacities[reverse_link] = self.flow_capacity[reverse_link]
            
            self.path_finder.build_graph()  # Rebuild the graph

            self.logger.error(f"Flow capacity restored.")
                
            return False
        
        self.logger.info(f"Applying flow reservation: {src_mac} -> {dst_mac}")

        try:
            src_port = self.host_to_switch[src_mac]['src_port']
        except KeyError:
            self.logger.error(f"Source port not found for host with MAC {src_mac}")
            return False

        try:
            dst_port = self.host_to_switch[dst_mac]['src_port']
        except KeyError:
            self.logger.error(f"Destination port not found for host with MAC {dst_mac}")
            return False
        
        # Install the flow rules
        self.install_path_flows(path, src_mac, dst_mac, src_port, dst_port, bandwidth)
        self.install_path_flows(path[::-1], dst_mac, src_mac, dst_port, src_port, bandwidth)
        
        self.logger.info(f"Flow successfully allocated from {src_mac} to {dst_mac}.")
        
        self.flow_reservations[(src_mac, dst_mac)]["installed"] = True

        return True

    def install_path_flows(self, path, src_mac, dst_mac, src_port, dst_port, bandwidth):
        """
        Installs flow rules along the given path.
        Args:
            path (list): List of switch IDs in the path.
            src_mac (str): Source MAC address.
            dst_mac (str): Destination MAC address.
            src_port (int): Source port.
            dst_port (int): Destination port.
        """
        for i in range(len(path)):
            datapath = self.get_datapath(path[i])
            parser = datapath.ofproto_parser

            try:
                if i == 0:
                    self.logger.info(f"First switch: {path[i]} -> {path[i + 1]}")
                    # First switch: match src_mac and forward to the next switch
                    out_port = self.links[(path[i], path[i + 1])]["src_port"]
                    match = parser.OFPMatch(eth_src=src_mac, eth_dst=dst_mac, in_port=src_port)
                elif i == len(path) - 1:
                    self.logger.info(f"Last switch: {path[i]} -> host B")
                    # Last switch: forward to destination port
                    out_port = dst_port
                    match = parser.OFPMatch(eth_src=src_mac, eth_dst=dst_mac)
                else:
                    self.logger.info(f"Intermediate switch: {path[i]} -> {path[i + 1]}")
                    # Intermediate switches
                    out_port = self.links[(path[i], path[i + 1])]["src_port"]
                    match = parser.OFPMatch(eth_src=src_mac, eth_dst=dst_mac)

               #  Apply QoS queue to enforce bandwidth limitation
                # queue_id = self.setup_qos_queue(datapath, out_port, bandwidth)
                
                queue_id = self.get_or_create_queue_id(datapath.id, out_port, bandwidth)
                actions = [parser.OFPActionSetQueue(queue_id), parser.OFPActionOutput(out_port)]
                self.add_flow(datapath, 1, match, actions)

            except KeyError:
                self.logger.error(f"Link not found: {path[i]} -> {path[i + 1]}")
                return

        self.logger.info(f"Flow rules installed along path: {path}")

    def delete_path_flows(self, path, src_mac, dst_mac):
        """
        Deletes flow rules along the given path.
        Args:
            path (list): List of switch IDs in the path.
            src_mac (str): Source MAC address.
            dst_mac (str): Destination MAC address.
        """
        for i in range(len(path)):
            datapath = self.get_datapath(path[i])
            parser = datapath.ofproto_parser

            try:
                if i == 0:
                    # First switch: match src_mac and forward to the next switch
                    match = parser.OFPMatch(eth_src=src_mac, eth_dst=dst_mac)
                elif i == len(path) - 1:
                    # Last switch: forward to destination port
                    match = parser.OFPMatch(eth_src=src_mac, eth_dst=dst_mac)
                else:
                    # Intermediate switches
                    match = parser.OFPMatch(eth_src=src_mac, eth_dst=dst_mac)

                self._delete_flow(datapath, match)

            except KeyError:
                self.logger.error(f"Link not found: {path[i]} -> {path[i + 1]}")
                return

        self.logger.info(f"Flow rules deleted along path: {path}")
    
    def get_or_create_queue_id(self, dpid, port, bandwidth):
        key = (dpid, port)
        
        # Initialize queues on this port if not already done
        if key not in self.qos_queues:
            self.qos_queues[key] = {}
        
        # Return existing queue ID if the bandwidth already exists
        for qid, bw in self.qos_queues[key].items():
            if bw == bandwidth:
                return qid

        # Otherwise, create a new queue ID (per-port)
        queue_id = max(self.qos_queues[key].keys(), default=0) + 1
        self.qos_queues[key][queue_id] = bandwidth

        # --- Build the full queue mapping for this port ---
        queue_refs = ",".join([f"{qid}=@q{qid}" for qid in self.qos_queues[key]])
        
        # --- Build the queue creation commands ---
        queue_creations = " ".join([
            f"-- --id=@q{qid} create Queue other-config:min-rate={bw * 1000000} other-config:max-rate={bw * 1000000} "
            for qid, bw in self.qos_queues[key].items()
        ])

        # Full OVS command: recreate QoS config with all queues attached
        ovs_cmd = (
            f"sudo ovs-vsctl -- set Port s{dpid}-eth{port} qos=@newqos "
            f"-- --id=@newqos create QoS type=linux-htb other-config:max-rate=1000000"
            f"queues={{{queue_refs}}} {queue_creations}"
        )

        self.logger.info(f"Creating/updating QoS on s{dpid}-eth{port} with queue {queue_id} ({bandwidth} Mbps)")
        os.system(ovs_cmd)

        return queue_id
 
    def get_datapath(self, switch_id):
        """
        Maps a switch ID to its datapath object.

        Args:
            switch_id (str): Switch ID.

        Returns:
            datapath: The OpenFlow datapath object for the switch.
        """        
        return self.datapaths[switch_id]

    @set_ev_cls(ofp_event.EventOFPPacketIn, MAIN_DISPATCHER)
    def packet_in_handler(self, ev):
        """
        Handles incoming packets in the OpenFlow controller.
        This method processes packets that arrive at the controller from switches. It performs
        the following main functions:
        - Extracts packet information (MAC addresses, switch info, ports)
        - Ignores LLDP and IPv6 packets
        - Checks if flow rules are already installed for the source-destination pair
        - Forwards packets based on known host locations
        - Implements packet forwarding with appropriate OpenFlow actions
        Parameters:
            ev (EventPacketIn): Event object containing the packet-in message from the switch
        """
        msg = ev.msg
        dp = msg.datapath
        dpid = dp.id
        parser = dp.ofproto_parser
        ofproto = dp.ofproto
        in_port = msg.match["in_port"]

        pkt = packet.Packet(msg.data)
        eth = pkt.get_protocol(ethernet.ethernet)
        
        if eth.ethertype in [ether_types.ETH_TYPE_LLDP, ether_types.ETH_TYPE_IPV6]:
            return  # Ignore LLDP and IPv6 packets 
        
        src_mac = eth.src
        dst_mac = eth.dst
    
        self.logger.info(f"PacketIn received: {eth.src} -> {eth.dst} on Switch {dpid}, Port {in_port}")
        
        installed = self.check_reservation(src_mac, dst_mac)

        if installed:
            self.logger.info(f"Flow rules installed, resending original packet from {src_mac} to {dst_mac}.")
            actions = [parser.OFPActionOutput(ofproto.OFPP_TABLE)]
            out = parser.OFPPacketOut(
                datapath=dp, buffer_id=msg.buffer_id, in_port=in_port, actions=actions, data=msg.data
            )
            dp.send_msg(out)
        else:
            self.logger.info(f"No flow rules installed, dropping packet from {src_mac} to {dst_mac}.")
            # Drop the packet if no flow rules are installed
            return
        